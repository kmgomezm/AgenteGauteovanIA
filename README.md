# Contexto
En los Ãºltimos aÃ±os Colombia experimentÃ³ transformaciones sociales, polÃ­ticas y econÃ³micas reflejadas en la opiniÃ³n pÃºblica. En el proyecto _Humanidades digitales y esfera pÃºblica_ de la Universidad EAFIT se recopilaron ~13k columnas de opiniÃ³n de periÃ³dicos colombianos (2018â€“2020).
- **Problema**: Los mÃ©todos tradicionales de anÃ¡lisis de opiniÃ³n son insuficientes para procesar grandes volÃºmenes de texto, extraer insights profundos con respuestas contextualizadas.
- **SoluciÃ³n**: Un agente conversacional autÃ³nomo que combina:
  - AnÃ¡lisis de sentimientos (detecciÃ³n de sarcasmo, emociones complejas).
  - GeneraciÃ³n de informes contextuales basados en RAG para evitar alucinaciones .
  - VisualizaciÃ³n interactiva de tendencias de opiniÃ³n.
- **PÃºblico Objetivo**: Periodistas, investigadores sociales, entidades gubernamentales y organizaciones de la sociedad civil.

# Agente Gauteovan IA

Ese proyecto propone la base para un agente conversacional multimodal, que integra anÃ¡lisis de texto con generaciÃ³n de visualizaciones (grÃ¡ficos, word clouds) y resÃºmenes. Es **100% local** (requisitos mÃ­nimos: 16 GB RAM | Intel core i5).

> Gauteovan es la diosa de todas las cosas en la cultura Tairona

## *Arquitectura del Sistema*

```mermaid
graph TD
    A[Usuario] --> B[Interfaz Web: Streamlit]
    B --> C[Backend: Agente LangChain]
    C --> D[Procesamiento de Consultas]
    D --> E[Retrieval: FAISS Vector Store]
    D --> F[LLM local: llama3.1]
    E --> G[Base de Conocimiento: Embeddings e5-small]
    F --> H[GeneraciÃ³n de Respuestas con RAG]
    H --> I[AnÃ¡lisis de Sentimientos: HF + spaCy]
    H --> J[GeneraciÃ³n de Visualizaciones]
    I --> K[Respuesta Multimodal]
    J --> K
    K --> B
```


## ğŸš€ Puesta en marcha (pasos mÃ­nimos)
1) **Instala dependencias**
Asegurate que que el directorio de trabajo estÃ¡ en el directorio de trabajo `cd C:\path\to\AgenteGauteovanIA`, una vez ahÃ­ crea el entorno virtual:
```bash
python -m venv .venv 
.venv\Scripts\activate
pip install -U pip
pip install -r requirements.txt
pip install ollama langchain langchain-community duckduckgo-search pandas
python -m spacy download es_core_news_lg
```
2) **Instala Ollama** y modelos locales (en otra terminal):
```bash
# https://ollama.com/download
ollama pull llama3.1:8b-instruct
```
3) **Construye los Ã­ndices** 
1. Ingesta: Lee el excel, lo limpia, divide en `chunks` sobrepuestos y guarda en un `.parket` con metadata: `'doc_id', 'autor', 'fecha', 'diario', 'tÃ­tulo', 'vÃ­nculo', 'row_idx', 'chunk',Â 'chunk_id'`
2. FAISS: Crea el Ã­ndice vectorial con FAISS para bÃºsqueda semÃ¡ntica, usando embeddings de `multilingual-e5-small`. Guarda el indice vectorial en `data/indexes/faiss.index` y los respectivos metadatos por `chunk`
3.  BM25: Crear el Ã­ndice lÃ©xico tipo BM25 para bÃºsqueda por keywords.


```bash
python scripts/build_index.py
```
5) **Lanza la app**

```bash
streamlit run app/streamlit_app.py
```

## ğŸ“ Estructura
```
colombia-opinion-agent/
â”œâ”€ app/
â”‚  â”œâ”€ streamlit_app.py
â”‚  â””â”€ pages/
â”‚     â”œâ”€ 1_Chat.py
â”‚     â”œâ”€ 2_Buscador_avanzado.py
â”‚     â”œâ”€ 3_Analisis_NLP.py
â”‚     â””â”€ 4_Reportes_y_Graficas.py
â”œâ”€ data/
â”‚  â”œâ”€ raw/Corpus_completo_revisado.xlsx      # (pon aquÃ­ tu archivo)
â”‚  â”œâ”€ processed/chunks.parquet  # (generado)
â”‚  â””â”€ indexes/
â”‚      â”œâ”€ faiss.index           # (generado)
â”‚      â”œâ”€ faiss_meta.parquet    # (generado)
â”‚      â””â”€ bm25.pkl              # (generado; o sqlite.db si migras a FTS5)
â”œâ”€ scripts/
â”‚  â”œâ”€ build_index.py
â”‚  â””â”€ eval_rag.py               # (plantilla)
â”œâ”€ src/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ ingest.py
â”‚  â”œâ”€ index_faiss.py
â”‚  â”œâ”€ index_bm25.py
â”‚  â”œâ”€ search_hybrid.py
â”‚  â”œâ”€ prompts.py
â”‚  â”œâ”€ rag_chain.py
â”‚  â”œâ”€ nlp_tools.py
â”‚  â”œâ”€ plots.py
â”‚  â””â”€ utils.py
â”œâ”€ tests/
â”œâ”€ requirements.txt
â””â”€ README.md
```

## ğŸ§  Conceptos clave
- **RAG hÃ­brido**: FAISS (embeddings `intfloat/multilingual-e5-small`) + BM25 (rank-bm25). FusiÃ³n con **RRF**.
- **Citas**: cada afirmaciÃ³n clave cita `[autor, periÃ³dico, fecha, tÃ­tulo, doc_id]`.
- **NLP**: spaCy (`es_core_news_lg`) para NER; BETO para sentimiento; zero-shot opcional para tÃ³picos.

## ğŸ“Œ Notas
- Este esqueleto corre **CPU-only**. Si tienes GPU, Transformers y Sentence-Transformers la aprovecharÃ¡n.
- Si tu Excel difiere, ajusta `src/ingest.py` (renombrado de columnas).
- Para resultados mÃ¡s â€œsegurosâ€, usa `temperature=0.2` en `rag_chain.py`.

## ğŸ§ª EvaluaciÃ³n (rÃ¡pida)
- Especifica 30â€“50 queries de prueba en `scripts/eval_rag.py`, mide `Recall@K` y latencias por etapa.
- Activa el logging en `app/streamlit_app.py` si quieres conservar conversaciones.

Â¡Listo para iterar! Cualquier mejora (FTS5, reranking, filtros UI) la puedes aÃ±adir sin romper el flujo base.
